{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quaternion CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhsukhendra/QuaternionCNN/blob/master/Quaternion_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Zc-Ubj3rq-",
        "colab_type": "code",
        "outputId": "c6b21dbd-91e2-475b-b7c5-28635539eed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! git clone https://github.com/Orkis-Research/Quaternion-Convolutional-Neural-Networks-for-End-to-End-Automatic-Speech-Recognition.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Quaternion-Convolutional-Neural-Networks-for-End-to-End-Automatic-Speech-Recognition'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Total 239 (delta 0), reused 0 (delta 0), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (239/239), 3.23 MiB | 4.91 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1RcAFFM7bM0",
        "colab_type": "code",
        "outputId": "ac476f5f-4daf-4467-a111-c7bf69187753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! python /content/Quaternion-Convolutional-Neural-Networks-for-End-to-End-Automatic-Speech-Recognition/Audio_Classification.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Train size : 739\n",
            "Dev size   : 174\n",
            "Test size  : 325\n",
            "Parameters    -------------------------------\n",
            "learning rate   : 0.0005\n",
            "Model type      : QCNN\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            " \n",
            "Model Summary ----------------------------\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 250, 4)            0         \n",
            "_________________________________________________________________\n",
            "quaternion_conv1d_1 (Quatern (None, 250, 128)          512       \n",
            "_________________________________________________________________\n",
            "average_pooling1d_1 (Average (None, 125, 128)          0         \n",
            "_________________________________________________________________\n",
            "quaternion_conv1d_2 (Quatern (None, 125, 256)          24832     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_2 (Average (None, 32, 256)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "quaternion_dense_1 (Quaterni (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 551,944\n",
            "Trainable params: 551,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 739 samples, validate on 174 samples\n",
            "Epoch 1/15\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-12-31 18:48:25.546440: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2019-12-31 18:48:25.560341: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n",
            "2019-12-31 18:48:25.563311: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3052bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-31 18:48:25.563351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-31 18:48:25.571517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-31 18:48:25.744026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-31 18:48:25.744654: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3052d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-31 18:48:25.744679: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2019-12-31 18:48:25.745971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-31 18:48:25.746487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-31 18:48:25.762785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-31 18:48:26.034770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-31 18:48:26.161352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-31 18:48:26.188592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-31 18:48:26.462089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-31 18:48:26.490800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-31 18:48:27.014278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-31 18:48:27.014463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-31 18:48:27.015191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-31 18:48:27.015766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-31 18:48:27.021694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-31 18:48:27.022921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-31 18:48:27.022979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-31 18:48:27.022998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-31 18:48:27.024343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-31 18:48:27.024873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-31 18:48:27.025370: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-31 18:48:27.025413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2019-12-31 18:48:33.581784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-31 18:48:35.078870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "739/739 [==============================] - 15s 21ms/step - loss: 1.0025 - acc: 0.6806 - val_loss: 0.6528 - val_acc: 0.8218\n",
            "Epoch 2/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.5355 - acc: 0.8214 - val_loss: 0.5012 - val_acc: 0.8448\n",
            "Epoch 3/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.4132 - acc: 0.8782 - val_loss: 0.4967 - val_acc: 0.8506\n",
            "Epoch 4/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.3421 - acc: 0.8890 - val_loss: 0.4681 - val_acc: 0.8276\n",
            "Epoch 5/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.2753 - acc: 0.9066 - val_loss: 0.4903 - val_acc: 0.8448\n",
            "Epoch 6/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.2053 - acc: 0.9256 - val_loss: 0.4620 - val_acc: 0.8391\n",
            "Epoch 7/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.1371 - acc: 0.9581 - val_loss: 0.5661 - val_acc: 0.8161\n",
            "Epoch 8/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.1161 - acc: 0.9608 - val_loss: 0.5242 - val_acc: 0.8333\n",
            "Epoch 9/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.0635 - acc: 0.9783 - val_loss: 0.5444 - val_acc: 0.8391\n",
            "Epoch 10/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.0683 - acc: 0.9838 - val_loss: 0.5364 - val_acc: 0.8391\n",
            "Epoch 11/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.0244 - acc: 0.9959 - val_loss: 0.5264 - val_acc: 0.8448\n",
            "Epoch 12/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.5350 - val_acc: 0.8563\n",
            "Epoch 13/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5669 - val_acc: 0.8506\n",
            "Epoch 14/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.8448\n",
            "Epoch 15/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 0.0531 - acc: 0.9811 - val_loss: 0.4936 - val_acc: 0.8563\n",
            "325/325 [==============================] - 0s 368us/step\n",
            "Test Loss = 0.7489397048950195 | Test accuracy = 0.8000000000916995\n",
            "That's All Folks :p \n",
            "Train size : 739\n",
            "Dev size   : 174\n",
            "Test size  : 325\n",
            "Parameters    -------------------------------\n",
            "learning rate   : 0.0005\n",
            "Model type      : CNN\n",
            " \n",
            "Model Summary ----------------------------\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 250, 3)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 250, 32)           320       \n",
            "_________________________________________________________________\n",
            "average_pooling1d_3 (Average (None, 125, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 125, 64)           6208      \n",
            "_________________________________________________________________\n",
            "average_pooling1d_4 (Average (None, 32, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 2056      \n",
            "=================================================================\n",
            "Total params: 533,128\n",
            "Trainable params: 533,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 739 samples, validate on 174 samples\n",
            "Epoch 1/15\n",
            "739/739 [==============================] - 1s 2ms/step - loss: 1.4869 - acc: 0.5061 - val_loss: 0.8847 - val_acc: 0.7586\n",
            "Epoch 2/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.6855 - acc: 0.7862 - val_loss: 0.5738 - val_acc: 0.8506\n",
            "Epoch 3/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.5274 - acc: 0.8363 - val_loss: 0.5832 - val_acc: 0.8391\n",
            "Epoch 4/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.4579 - acc: 0.8512 - val_loss: 0.5204 - val_acc: 0.8448\n",
            "Epoch 5/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.4213 - acc: 0.8633 - val_loss: 0.4751 - val_acc: 0.8506\n",
            "Epoch 6/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.3882 - acc: 0.8782 - val_loss: 0.5466 - val_acc: 0.8391\n",
            "Epoch 7/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.3667 - acc: 0.8796 - val_loss: 0.5364 - val_acc: 0.8333\n",
            "Epoch 8/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.3191 - acc: 0.8945 - val_loss: 0.4729 - val_acc: 0.8448\n",
            "Epoch 9/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.2966 - acc: 0.9039 - val_loss: 0.5290 - val_acc: 0.8276\n",
            "Epoch 10/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.2652 - acc: 0.9147 - val_loss: 0.5083 - val_acc: 0.8391\n",
            "Epoch 11/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.2550 - acc: 0.9107 - val_loss: 0.4773 - val_acc: 0.8333\n",
            "Epoch 12/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.2284 - acc: 0.9269 - val_loss: 0.4500 - val_acc: 0.8621\n",
            "Epoch 13/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.2088 - acc: 0.9310 - val_loss: 0.4830 - val_acc: 0.8391\n",
            "Epoch 14/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.1831 - acc: 0.9337 - val_loss: 0.6174 - val_acc: 0.8218\n",
            "Epoch 15/15\n",
            "739/739 [==============================] - 1s 1ms/step - loss: 0.1591 - acc: 0.9405 - val_loss: 0.5500 - val_acc: 0.8218\n",
            "325/325 [==============================] - 0s 118us/step\n",
            "Test Loss = 0.6678010933215801 | Test accuracy = 0.8030769231227728\n",
            "That's All Folks :p \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjHSYMIR90IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile, os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3r4_Bd2W3NJ",
        "colab_type": "code",
        "outputId": "1336e5c7-403f-4751-ab10-415e6391133e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! unzip /content/Quaternion-Convolutional-Neural-Networks-for-End-to-End-Automatic-Speech-Recognition/db.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Quaternion-Convolutional-Neural-Networks-for-End-to-End-Automatic-Speech-Recognition/db.zip\n",
            "  inflating: donnees du TP/scalogramme_ARR.png  \n",
            "  inflating: donnees du TP/README.txt  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_122.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_126.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_98.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_99.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_125.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_97.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_124.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_123.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_118.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_120.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_121.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_113.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_108.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_117.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_119.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_112.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_110.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_109.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_115.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_105.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_106.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_103.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_114.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_102.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_104.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_116.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_111.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_100.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_107.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_159.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_158.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_160.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_150.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_155.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_162.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_161.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_153.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_149.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_156.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_154.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_151.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_148.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_157.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_146.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_141.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_143.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_139.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_138.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_145.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_152.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_147.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_142.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/CHF/CHF_101.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_136.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_144.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_140.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_95.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_135.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_131.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_129.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_137.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_133.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_134.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_91.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_132.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_96.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_130.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_86.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_92.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_127.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_9.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_90.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/NSR/NSR_128.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_8.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_81.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_85.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_79.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_84.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_76.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_93.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_82.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_83.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_94.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_80.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_89.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_74.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_75.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_88.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_68.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_7.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_72.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_73.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_59.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_6.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_61.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_70.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_69.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_65.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_71.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_64.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_66.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_54.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_67.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_77.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_60.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_5.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_53.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_57.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_62.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_50.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_48.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_58.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_51.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_56.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_55.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_39.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_49.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_44.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_52.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_47.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_46.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_63.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_37.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_43.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_34.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_40.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_41.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_42.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_29.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_28.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_38.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_4.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_27.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_32.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_30.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_31.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_3.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_20.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_35.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_45.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_2.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_24.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_22.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_33.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_78.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_12.jpg  \n",
            "  inflating: donnees du TP/ECGData.mat  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_13.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_15.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_19.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_17.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_16.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_11.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_26.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_25.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_21.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_23.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_18.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_14.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_36.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_87.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_1.jpg  \n",
            "  inflating: donnees du TP/scalogrammes/ARR/ARR_10.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZvMoQyNpPbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTe18G_KqC84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RgbToQuaternion(img):\n",
        " b,g,r = cv2.split(img)\n",
        " \n",
        " M=[]\n",
        " for i in range(r.shape[0]):\n",
        "  t=[]\n",
        "  for j in range(r.shape[1]):\n",
        "   t.append([0.0,r[i][j],g[i][j],b[i][j]])\n",
        "  M.append(t)\n",
        " M=np.array(M)/255.\n",
        " return(np.array(M))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM-5xfNIqICI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def QuaternionToRgb(img):\n",
        "\n",
        " M=[]\n",
        " for i in range(img.shape[0]):\n",
        "  t=[]\n",
        "  for j in range(img.shape[1]):\n",
        "   t.append([img[i][j][3],img[i][j][2],img[i][j][1]])\n",
        "  M.append(t)\n",
        " M=np.array(M)*255\n",
        " return(np.array(M))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVx9Z07eqO_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATADIR = \"/content/donnees du TP/scalogrammes\"\n",
        "CATEGORIES = [\"ARR\", \"CHF\",\"NSR\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKJpElR8qZx4",
        "colab_type": "code",
        "outputId": "3151d063-7152-4cde-a951-281037fabb04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "training_data = []\n",
        "allI1= []\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:  # do dogs and cats\n",
        "\n",
        "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img) )  # convert to array\n",
        "                allI1.append(img_array)\n",
        "                training_data.append([RgbToQuaternion(img_array), class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "            #except OSError as e:\n",
        "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "            #except Exception as e:\n",
        "            #    print(\"general exception\", e, os.path.join(path,img))\n",
        "\n",
        "create_training_data()\n",
        "import random\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "allI1 = np.array(allI1)\n",
        "X = np.array(X)\n",
        "\n",
        "y=np.array(y)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [00:09<00:00, 10.56it/s]\n",
            "100%|██████████| 30/30 [00:02<00:00, 10.47it/s]\n",
            "100%|██████████| 36/36 [00:03<00:00, 10.62it/s]\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijo8AkuMXR3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator( rotation_range=90,width_shift_range=0.1, height_shift_range=0.1,horizontal_flip=True)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukMq7W-CYNDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy                 as np\n",
        "import keras                        \n",
        "from   keras.optimizers      import *\n",
        "from   keras.layers                          import *\n",
        "from   keras.models                          import Model\n",
        "import keras.backend                         as     K\n",
        "from   Quaternion.complexnn             import *\n",
        "from   sklearn.preprocessing import normalize\n",
        "import sys\n",
        "import argparse              as Ap\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oscIt2jlZNAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "opt = adam(lr = 0.001,decay=1e-6)\n",
        "dense_layers = [2]\n",
        "layer_sizes = [64]\n",
        "conv_layers = [3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjKnVO3rZSwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "import keras\n",
        "from keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler\n",
        "import logging as L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf0VnoWEZYEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Keep a history of the validation performance.\n",
        "class TrainValHistory(Callback):\n",
        "\tdef __init__(self):\n",
        "\t\tself.train_loss = []\n",
        "\t\tself.train_acc  = []\n",
        "\t\tself.val_loss   = []\n",
        "\t\tself.val_acc    = []\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tself.train_loss.append(logs.get('loss'))\n",
        "\t\tself.train_acc .append(logs.get('acc'))\n",
        "\t\tself.val_loss  .append(logs.get('val_loss'))\n",
        "\t\tself.val_acc   .append(logs.get('val_acc'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruJJydSOZeLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_loss1 = []\n",
        "train_acc1  = []\n",
        "val_loss1   = []\n",
        "val_acc1    = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E54pIq3aBq_",
        "colab_type": "code",
        "outputId": "9468fc90-a7df-4dbc-d6f0-a708efdbc450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            NAME = \"QCNN-{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
        "            print(NAME)\n",
        "            input_seq = Input((224, 224, 4))\n",
        "            O    =QuaternionConv2D(layer_size, (5,5),activation='relu',padding='same')(input_seq)  \n",
        "            O    = MaxPooling2D((4,4), padding='same')(O)\n",
        "            for l in range(conv_layer-1):\n",
        "              O    =QuaternionConv2D(layer_size, (5,5),activation='relu',padding='same')(O)  \n",
        "              O    = MaxPooling2D((4,4), padding='same')(O)\n",
        "            O    = Flatten()(O)\n",
        "            for _ in range(dense_layer):\n",
        "              O  = QuaternionDense(layer_size, activation='relu')(O)\n",
        "            \n",
        "            O = Dense(3, activation='softmax')(O)\n",
        "            model=Model(input_seq, O)\n",
        "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "            model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "            trainValHistCb = TrainValHistory()\n",
        "            mode=\"quaternion\"\n",
        "            callbacks = [trainValHistCb,tensorboard]\n",
        "            model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\\\n",
        "                    steps_per_epoch=X.shape[0] // 32,epochs=100,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=callbacks)\n",
        "            \n",
        "            train_loss1 = np.asarray(trainValHistCb.train_loss)\n",
        "            train_acc1  = np.asarray(trainValHistCb.train_acc)\n",
        "            val_loss1   = np.asarray(trainValHistCb.val_loss)\n",
        "            val_acc1    = np.asarray(trainValHistCb.val_acc)\n",
        "            \n",
        "            np.savetxt('{}_train_loss.txt'.format(mode), np.asarray(trainValHistCb.train_loss))\n",
        "            np.savetxt('{}_train_acc.txt'.format(mode), np.asarray(trainValHistCb.train_acc))\n",
        "            np.savetxt('{}_val_loss.txt'.format(mode), np.asarray(trainValHistCb.val_loss))\n",
        "            np.savetxt('{}_val_acc.txt'.format(mode), np.asarray(trainValHistCb.val_acc))\n",
        "            #model.fit(x_train, y_train,validation_split=0.3,callbacks=[tensorboard],epochs=50,batch_size=32)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QCNN-3-conv-64-nodes-2-dense-1577820159\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "5/5 [==============================] - 6s 1s/step - loss: 1.9073 - acc: 0.6103 - val_loss: 1.6938 - val_acc: 0.4898\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 1.0065 - acc: 0.6072 - val_loss: 1.0045 - val_acc: 0.4898\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.9323 - acc: 0.6072 - val_loss: 1.0228 - val_acc: 0.4898\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.8874 - acc: 0.6489 - val_loss: 1.0325 - val_acc: 0.4898\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.8671 - acc: 0.6164 - val_loss: 0.9279 - val_acc: 0.4898\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.8235 - acc: 0.6517 - val_loss: 0.8910 - val_acc: 0.5714\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 0.8415 - acc: 0.7112 - val_loss: 0.9160 - val_acc: 0.4898\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.7848 - acc: 0.6609 - val_loss: 0.9835 - val_acc: 0.6122\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 2s 417ms/step - loss: 0.7669 - acc: 0.7146 - val_loss: 0.9522 - val_acc: 0.5918\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.7666 - acc: 0.7135 - val_loss: 0.8894 - val_acc: 0.5918\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 0.7790 - acc: 0.7334 - val_loss: 0.8470 - val_acc: 0.6531\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.6997 - acc: 0.6782 - val_loss: 0.7811 - val_acc: 0.6531\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 410ms/step - loss: 0.7818 - acc: 0.6962 - val_loss: 0.8024 - val_acc: 0.6531\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 2s 364ms/step - loss: 0.7387 - acc: 0.7074 - val_loss: 0.7815 - val_acc: 0.6327\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.7170 - acc: 0.7527 - val_loss: 0.8712 - val_acc: 0.5918\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 2s 401ms/step - loss: 0.6853 - acc: 0.7400 - val_loss: 0.9206 - val_acc: 0.6531\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6820 - acc: 0.7273 - val_loss: 0.9126 - val_acc: 0.6122\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 364ms/step - loss: 0.6032 - acc: 0.7536 - val_loss: 1.0246 - val_acc: 0.6327\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 2s 444ms/step - loss: 0.7118 - acc: 0.7250 - val_loss: 0.7924 - val_acc: 0.6327\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 2s 358ms/step - loss: 0.6947 - acc: 0.7361 - val_loss: 0.8487 - val_acc: 0.6735\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 414ms/step - loss: 0.7289 - acc: 0.6955 - val_loss: 0.8235 - val_acc: 0.6122\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 0.6577 - acc: 0.7593 - val_loss: 0.7529 - val_acc: 0.6531\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.6630 - acc: 0.7273 - val_loss: 0.8344 - val_acc: 0.6531\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.5671 - acc: 0.7810 - val_loss: 0.7538 - val_acc: 0.6531\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 2s 416ms/step - loss: 0.5811 - acc: 0.7845 - val_loss: 0.7259 - val_acc: 0.6735\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.5983 - acc: 0.7400 - val_loss: 0.7566 - val_acc: 0.6735\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 0.5053 - acc: 0.8194 - val_loss: 0.8175 - val_acc: 0.6735\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6015 - acc: 0.7481 - val_loss: 0.7886 - val_acc: 0.6531\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 380ms/step - loss: 0.6080 - acc: 0.6917 - val_loss: 0.5661 - val_acc: 0.6939\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 2s 446ms/step - loss: 0.5435 - acc: 0.8063 - val_loss: 0.8358 - val_acc: 0.6531\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 0.5496 - acc: 0.8010 - val_loss: 0.8723 - val_acc: 0.6531\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.5348 - acc: 0.7983 - val_loss: 0.6002 - val_acc: 0.6735\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 0.5296 - acc: 0.8159 - val_loss: 0.6482 - val_acc: 0.7143\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.4329 - acc: 0.8400 - val_loss: 0.6088 - val_acc: 0.6939\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.5518 - acc: 0.7510 - val_loss: 0.7266 - val_acc: 0.6735\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 2s 394ms/step - loss: 0.4836 - acc: 0.8071 - val_loss: 0.7618 - val_acc: 0.6939\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 418ms/step - loss: 0.5221 - acc: 0.8054 - val_loss: 0.6276 - val_acc: 0.6735\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 371ms/step - loss: 0.4339 - acc: 0.8159 - val_loss: 0.7502 - val_acc: 0.6735\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.4101 - acc: 0.8417 - val_loss: 0.8187 - val_acc: 0.6735\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.4772 - acc: 0.7863 - val_loss: 0.5064 - val_acc: 0.8163\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 2s 424ms/step - loss: 0.4130 - acc: 0.8336 - val_loss: 1.0714 - val_acc: 0.6327\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 0.5600 - acc: 0.8175 - val_loss: 0.5753 - val_acc: 0.7347\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.4775 - acc: 0.8000 - val_loss: 0.5417 - val_acc: 0.8163\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 363ms/step - loss: 0.4457 - acc: 0.8277 - val_loss: 0.5222 - val_acc: 0.8163\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.4287 - acc: 0.8446 - val_loss: 0.6794 - val_acc: 0.7347\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.4198 - acc: 0.8400 - val_loss: 0.7455 - val_acc: 0.7347\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 0.4357 - acc: 0.7991 - val_loss: 0.5673 - val_acc: 0.7347\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.4139 - acc: 0.8008 - val_loss: 0.6040 - val_acc: 0.7347\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 419ms/step - loss: 0.3006 - acc: 0.8591 - val_loss: 0.5532 - val_acc: 0.7959\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 0.3464 - acc: 0.8564 - val_loss: 0.5414 - val_acc: 0.8367\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.3626 - acc: 0.8319 - val_loss: 0.9966 - val_acc: 0.6531\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 2s 416ms/step - loss: 0.5073 - acc: 0.7909 - val_loss: 0.5318 - val_acc: 0.7959\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.4518 - acc: 0.8446 - val_loss: 0.7193 - val_acc: 0.7347\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.3655 - acc: 0.8654 - val_loss: 0.6379 - val_acc: 0.7347\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 377ms/step - loss: 0.3362 - acc: 0.8713 - val_loss: 0.7135 - val_acc: 0.7143\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.4201 - acc: 0.8244 - val_loss: 0.5525 - val_acc: 0.7755\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 0.3543 - acc: 0.8518 - val_loss: 0.4127 - val_acc: 0.7959\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.3431 - acc: 0.8481 - val_loss: 0.4800 - val_acc: 0.7755\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.3051 - acc: 0.8781 - val_loss: 0.4868 - val_acc: 0.8367\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.4194 - acc: 0.8343 - val_loss: 0.5095 - val_acc: 0.8367\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 2s 414ms/step - loss: 0.4391 - acc: 0.7937 - val_loss: 0.8723 - val_acc: 0.6735\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.4264 - acc: 0.8209 - val_loss: 0.4274 - val_acc: 0.8367\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 371ms/step - loss: 0.4212 - acc: 0.8231 - val_loss: 0.5338 - val_acc: 0.7755\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.3581 - acc: 0.8336 - val_loss: 0.4963 - val_acc: 0.7959\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 385ms/step - loss: 0.3442 - acc: 0.8759 - val_loss: 0.4415 - val_acc: 0.8163\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 2s 446ms/step - loss: 0.3395 - acc: 0.8563 - val_loss: 0.4465 - val_acc: 0.7959\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 2s 374ms/step - loss: 0.3957 - acc: 0.8648 - val_loss: 0.5437 - val_acc: 0.7551\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.3180 - acc: 0.8781 - val_loss: 0.5897 - val_acc: 0.7551\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 419ms/step - loss: 0.3217 - acc: 0.8735 - val_loss: 0.6545 - val_acc: 0.7959\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 0.2555 - acc: 0.8740 - val_loss: 0.6291 - val_acc: 0.7551\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 445ms/step - loss: 0.2941 - acc: 0.9000 - val_loss: 0.4469 - val_acc: 0.8367\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 0.3088 - acc: 0.8935 - val_loss: 0.6838 - val_acc: 0.7347\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 0.2783 - acc: 0.9148 - val_loss: 0.5395 - val_acc: 0.7755\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 446ms/step - loss: 0.3383 - acc: 0.8375 - val_loss: 0.8294 - val_acc: 0.7755\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 0.2345 - acc: 0.9213 - val_loss: 0.6192 - val_acc: 0.7755\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 401ms/step - loss: 0.3116 - acc: 0.8573 - val_loss: 0.5516 - val_acc: 0.8163\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 2s 360ms/step - loss: 0.2954 - acc: 0.8518 - val_loss: 0.5866 - val_acc: 0.8163\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 2s 449ms/step - loss: 0.2877 - acc: 0.8688 - val_loss: 0.7275 - val_acc: 0.7551\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 0.2042 - acc: 0.9102 - val_loss: 0.5123 - val_acc: 0.7959\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.3035 - acc: 0.8937 - val_loss: 0.4148 - val_acc: 0.8571\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.2610 - acc: 0.9191 - val_loss: 0.6819 - val_acc: 0.7755\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 2s 401ms/step - loss: 0.2631 - acc: 0.8891 - val_loss: 0.6569 - val_acc: 0.7755\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.2358 - acc: 0.9237 - val_loss: 0.7724 - val_acc: 0.7347\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 2s 360ms/step - loss: 0.2597 - acc: 0.8935 - val_loss: 0.6107 - val_acc: 0.7551\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 0.1795 - acc: 0.9370 - val_loss: 0.7011 - val_acc: 0.7347\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 2s 451ms/step - loss: 0.2290 - acc: 0.9000 - val_loss: 0.5254 - val_acc: 0.7755\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 2s 361ms/step - loss: 0.1640 - acc: 0.9454 - val_loss: 0.8203 - val_acc: 0.7143\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.1759 - acc: 0.9226 - val_loss: 0.4141 - val_acc: 0.8163\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 2s 378ms/step - loss: 0.2050 - acc: 0.9175 - val_loss: 0.8172 - val_acc: 0.7347\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.1547 - acc: 0.9191 - val_loss: 0.7559 - val_acc: 0.7551\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.1607 - acc: 0.9463 - val_loss: 0.4708 - val_acc: 0.8367\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.1888 - acc: 0.9226 - val_loss: 0.5272 - val_acc: 0.8163\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.2466 - acc: 0.8972 - val_loss: 0.9940 - val_acc: 0.7143\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.2337 - acc: 0.9064 - val_loss: 0.7042 - val_acc: 0.7959\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 0.2633 - acc: 0.9213 - val_loss: 0.7863 - val_acc: 0.7755\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.2589 - acc: 0.9000 - val_loss: 0.7256 - val_acc: 0.7755\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 2s 382ms/step - loss: 0.1806 - acc: 0.9343 - val_loss: 0.7281 - val_acc: 0.7755\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.3246 - acc: 0.8463 - val_loss: 0.4810 - val_acc: 0.7959\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.3070 - acc: 0.8619 - val_loss: 0.6812 - val_acc: 0.7551\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.2367 - acc: 0.8990 - val_loss: 0.4794 - val_acc: 0.8163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCu2Nlq-aVkI",
        "colab_type": "code",
        "outputId": "1c71ce12-00ec-4cec-8a63-cfbb866d36a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "train_loss1 = np.asarray(train_loss1.train_loss)\n",
        "train_acc1  = np.asarray(train_acc1.train_acc)\n",
        "val_loss1   = np.asarray(val_loss1.val_loss)\n",
        "val_acc1    = np.asarray(val_acc1.val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5033f86ce748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_acc1\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_loss1\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_acc1\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'train_loss'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNqS5lwpaZv-",
        "colab_type": "code",
        "outputId": "28309dca-1b5a-4e45-9c2d-a20d83568473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "predictions = model.predict(X)\n",
        "y_pred = (predictions > 0.5)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix =confusion_matrix(y, y_pred.argmax(axis=1))/1.\n",
        "matrix[0,]=matrix[0,]/np.sum(matrix[0,])\n",
        "matrix[1,]=matrix[1,]/np.sum(matrix[1,])\n",
        "matrix[2,]=matrix[2,]/np.sum(matrix[2,])\n",
        "matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9375    , 0.04166667, 0.02083333],\n",
              "       [0.13333333, 0.86666667, 0.        ],\n",
              "       [0.05555556, 0.        , 0.94444444]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyxe7KuXae3q",
        "colab_type": "code",
        "outputId": "4e0b2d81-60d6-4235-d788-4d0d44558df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.21.3)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.1.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->scikit-plot) (1.17.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (42.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.12.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAWYSxiRahnD",
        "colab_type": "code",
        "outputId": "5d232047-f11f-4cf8-ab30-7179128f0a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "skplt.metrics.plot_roc_curve(y, predictions)\n",
        "plt.show()\n",
        "plt.savefig('Roc.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:85: DeprecationWarning: Function plot_roc_curve is deprecated; This will be removed in v0.5.0. Please use scikitplot.metrics.plot_roc instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QQmDTiFan60",
        "colab_type": "code",
        "outputId": "3e76d7c7-f676-4d13-8ee1-c01debe0405e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "training_data = []\n",
        "allI2= []\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:  # do dogs and cats\n",
        "\n",
        "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img) )  # convert to array\n",
        "                allI2.append(img_array) \n",
        "                training_data.append([img_array, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "            #except OSError as e:\n",
        "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "            #except Exception as e:\n",
        "            #    print(\"general exception\", e, os.path.join(path,img))\n",
        "\n",
        "create_training_data()\n",
        "import random\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "allI2 = np.array(allI2)\n",
        "X = np.array(X)/255.\n",
        "y=np.array(y)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [00:00<00:00, 1145.68it/s]\n",
            "100%|██████████| 30/30 [00:00<00:00, 1383.45it/s]\n",
            "100%|██████████| 36/36 [00:00<00:00, 1492.59it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl-oceNYc9kV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator( rotation_range=90,width_shift_range=0.1, height_shift_range=0.1,horizontal_flip=True)\n",
        "datagen.fit(x_train)\n",
        "opt = Adam(lr = 0.0001,decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrXdhEd4awBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysu5ageoa0hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dense_layers = [2]\n",
        "layer_sizes = [64]\n",
        "conv_layers = [3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq-rd0P_a6Z5",
        "colab_type": "code",
        "outputId": "21718ef5-a81a-40d7-b55c-c89dc4bbff21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            NAME = \"CNN-{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
        "            print(NAME)\n",
        "\n",
        "            model = Sequential()\n",
        "\n",
        "            model.add(Conv2D(layer_size, (5, 5), input_shape=x_train.shape[1:]))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "\n",
        "            for l in range(conv_layer-1):\n",
        "                model.add(Conv2D(layer_size, (5, 5)))\n",
        "                model.add(Activation('relu'))\n",
        "                model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "\n",
        "            model.add(Flatten())\n",
        "\n",
        "            for _ in range(dense_layer):\n",
        "                model.add(Dense(512))\n",
        "                model.add(Activation('relu'))\n",
        "                model.add(Dropout(0.2))\n",
        "\n",
        "            model.add(Dense(3))\n",
        "            model.add(Activation('sigmoid'))\n",
        "\n",
        "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "            model.compile(loss='categorical_crossentropy',\n",
        "                          optimizer=opt,\n",
        "                          metrics=['accuracy'],\n",
        "                          )\n",
        "\n",
        "            model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\\\n",
        "                    steps_per_epoch=X.shape[0] // 32,epochs=200,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[tensorboard])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN-3-conv-64-nodes-2-dense-1577820611\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 2s 391ms/step - loss: 1.0727 - acc: 0.5517 - val_loss: 1.0265 - val_acc: 0.6327\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 1.0401 - acc: 0.5343 - val_loss: 0.9568 - val_acc: 0.6327\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.9597 - acc: 0.5991 - val_loss: 0.9000 - val_acc: 0.6327\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.9653 - acc: 0.5535 - val_loss: 0.9084 - val_acc: 0.6327\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.9339 - acc: 0.5990 - val_loss: 0.9020 - val_acc: 0.6327\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.9460 - acc: 0.5627 - val_loss: 0.8831 - val_acc: 0.6327\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 2s 309ms/step - loss: 0.9314 - acc: 0.5750 - val_loss: 0.8778 - val_acc: 0.6327\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.9105 - acc: 0.5971 - val_loss: 0.8755 - val_acc: 0.6327\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.9440 - acc: 0.5645 - val_loss: 0.8713 - val_acc: 0.6327\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.8922 - acc: 0.6100 - val_loss: 0.8702 - val_acc: 0.6327\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.9086 - acc: 0.5638 - val_loss: 0.8739 - val_acc: 0.6327\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.9178 - acc: 0.5722 - val_loss: 0.8660 - val_acc: 0.6327\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.9223 - acc: 0.5528 - val_loss: 0.8601 - val_acc: 0.6327\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.8782 - acc: 0.6136 - val_loss: 0.8641 - val_acc: 0.6327\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.9565 - acc: 0.5260 - val_loss: 0.8833 - val_acc: 0.6327\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.8773 - acc: 0.6019 - val_loss: 0.8816 - val_acc: 0.6327\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.8759 - acc: 0.6009 - val_loss: 0.8626 - val_acc: 0.6327\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 0.8992 - acc: 0.5750 - val_loss: 0.8600 - val_acc: 0.6327\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.8669 - acc: 0.6009 - val_loss: 0.8605 - val_acc: 0.6531\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.8715 - acc: 0.5691 - val_loss: 0.8733 - val_acc: 0.6735\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 1s 287ms/step - loss: 0.9035 - acc: 0.5673 - val_loss: 0.8724 - val_acc: 0.6939\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.8490 - acc: 0.6464 - val_loss: 0.8662 - val_acc: 0.6939\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.8506 - acc: 0.6241 - val_loss: 0.8571 - val_acc: 0.6939\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.8260 - acc: 0.6227 - val_loss: 0.8939 - val_acc: 0.6327\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 1s 288ms/step - loss: 0.8181 - acc: 0.6591 - val_loss: 0.8461 - val_acc: 0.6327\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.8201 - acc: 0.6482 - val_loss: 0.8112 - val_acc: 0.6939\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.8781 - acc: 0.5955 - val_loss: 0.9014 - val_acc: 0.5102\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.8601 - acc: 0.6263 - val_loss: 0.8360 - val_acc: 0.6327\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.8610 - acc: 0.6408 - val_loss: 0.8071 - val_acc: 0.6531\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.7436 - acc: 0.7192 - val_loss: 0.9165 - val_acc: 0.6327\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.8354 - acc: 0.6501 - val_loss: 0.8729 - val_acc: 0.6122\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.8106 - acc: 0.5818 - val_loss: 0.8268 - val_acc: 0.6327\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 0.7914 - acc: 0.6581 - val_loss: 0.8523 - val_acc: 0.6122\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 1s 299ms/step - loss: 0.8769 - acc: 0.6210 - val_loss: 0.8779 - val_acc: 0.6122\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.7768 - acc: 0.6620 - val_loss: 0.8281 - val_acc: 0.6531\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.7385 - acc: 0.7231 - val_loss: 0.8315 - val_acc: 0.6327\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.7631 - acc: 0.7342 - val_loss: 0.8642 - val_acc: 0.6327\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 0.7883 - acc: 0.6375 - val_loss: 0.8284 - val_acc: 0.6531\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.7163 - acc: 0.7055 - val_loss: 0.8704 - val_acc: 0.6327\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.8163 - acc: 0.6690 - val_loss: 0.8065 - val_acc: 0.6531\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 0.8014 - acc: 0.6644 - val_loss: 0.8327 - val_acc: 0.6122\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.7725 - acc: 0.6701 - val_loss: 0.8426 - val_acc: 0.6327\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.6275 - acc: 0.7407 - val_loss: 0.9197 - val_acc: 0.5306\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.7547 - acc: 0.7036 - val_loss: 0.8668 - val_acc: 0.5510\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 1s 287ms/step - loss: 0.7219 - acc: 0.6817 - val_loss: 0.8599 - val_acc: 0.5714\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.7989 - acc: 0.6417 - val_loss: 0.8903 - val_acc: 0.5714\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.6921 - acc: 0.7383 - val_loss: 0.9251 - val_acc: 0.5510\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.8184 - acc: 0.6326 - val_loss: 0.8429 - val_acc: 0.6122\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.7485 - acc: 0.6260 - val_loss: 0.8503 - val_acc: 0.5714\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.7437 - acc: 0.7118 - val_loss: 0.8406 - val_acc: 0.6531\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.7084 - acc: 0.6782 - val_loss: 0.8305 - val_acc: 0.6531\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 1s 295ms/step - loss: 0.6964 - acc: 0.7181 - val_loss: 0.8670 - val_acc: 0.5714\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 1s 288ms/step - loss: 0.7250 - acc: 0.7047 - val_loss: 0.8086 - val_acc: 0.5918\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.6857 - acc: 0.7223 - val_loss: 0.8275 - val_acc: 0.5918\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 0.6908 - acc: 0.7313 - val_loss: 0.9142 - val_acc: 0.6327\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.6623 - acc: 0.7120 - val_loss: 0.8595 - val_acc: 0.5918\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.7031 - acc: 0.7445 - val_loss: 0.8667 - val_acc: 0.6122\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 2s 306ms/step - loss: 0.7350 - acc: 0.6500 - val_loss: 0.8448 - val_acc: 0.6327\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.6431 - acc: 0.7250 - val_loss: 0.8270 - val_acc: 0.6122\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.6747 - acc: 0.6662 - val_loss: 0.7926 - val_acc: 0.6939\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.6745 - acc: 0.7354 - val_loss: 0.8072 - val_acc: 0.6531\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.6313 - acc: 0.7008 - val_loss: 0.8505 - val_acc: 0.6327\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.5797 - acc: 0.7491 - val_loss: 1.0239 - val_acc: 0.5510\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.7086 - acc: 0.6817 - val_loss: 0.8086 - val_acc: 0.6122\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.6748 - acc: 0.7323 - val_loss: 0.8639 - val_acc: 0.6327\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.7570 - acc: 0.6408 - val_loss: 0.9538 - val_acc: 0.5714\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 1s 300ms/step - loss: 0.5783 - acc: 0.7736 - val_loss: 0.8037 - val_acc: 0.6531\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.7640 - acc: 0.6563 - val_loss: 0.7799 - val_acc: 0.6735\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.6657 - acc: 0.6627 - val_loss: 0.8684 - val_acc: 0.6531\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.6096 - acc: 0.7418 - val_loss: 0.8361 - val_acc: 0.6531\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.6433 - acc: 0.7250 - val_loss: 0.8632 - val_acc: 0.6735\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.6214 - acc: 0.7563 - val_loss: 0.8193 - val_acc: 0.6735\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 2s 301ms/step - loss: 0.5684 - acc: 0.7891 - val_loss: 0.8575 - val_acc: 0.6531\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.7306 - acc: 0.6620 - val_loss: 0.8084 - val_acc: 0.6531\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.5743 - acc: 0.7445 - val_loss: 0.8147 - val_acc: 0.6327\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 1s 298ms/step - loss: 0.5943 - acc: 0.7100 - val_loss: 0.9001 - val_acc: 0.6122\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 0.5666 - acc: 0.7273 - val_loss: 0.8516 - val_acc: 0.6531\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.6404 - acc: 0.7250 - val_loss: 0.8397 - val_acc: 0.6327\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 0.5900 - acc: 0.7313 - val_loss: 0.8259 - val_acc: 0.6327\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.5511 - acc: 0.7464 - val_loss: 0.8169 - val_acc: 0.6531\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 1s 288ms/step - loss: 0.5567 - acc: 0.7580 - val_loss: 0.8591 - val_acc: 0.6531\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.5631 - acc: 0.7602 - val_loss: 0.9329 - val_acc: 0.6327\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.5573 - acc: 0.7639 - val_loss: 0.9275 - val_acc: 0.6531\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.5955 - acc: 0.7245 - val_loss: 0.9376 - val_acc: 0.6531\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.6086 - acc: 0.7736 - val_loss: 0.8480 - val_acc: 0.6122\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.5422 - acc: 0.7915 - val_loss: 1.0017 - val_acc: 0.6531\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.5926 - acc: 0.7153 - val_loss: 0.8317 - val_acc: 0.6122\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.5423 - acc: 0.7619 - val_loss: 0.9302 - val_acc: 0.6122\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.5907 - acc: 0.7291 - val_loss: 0.8397 - val_acc: 0.6735\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.5793 - acc: 0.6871 - val_loss: 0.8705 - val_acc: 0.6735\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.5702 - acc: 0.7626 - val_loss: 0.8502 - val_acc: 0.6735\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.4764 - acc: 0.8191 - val_loss: 0.7788 - val_acc: 0.6735\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 2s 303ms/step - loss: 0.5038 - acc: 0.7729 - val_loss: 0.9550 - val_acc: 0.6735\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.5080 - acc: 0.7823 - val_loss: 0.8929 - val_acc: 0.6531\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 2s 325ms/step - loss: 0.5373 - acc: 0.7625 - val_loss: 0.9274 - val_acc: 0.6531\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.5618 - acc: 0.7677 - val_loss: 0.7631 - val_acc: 0.6122\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.5331 - acc: 0.7782 - val_loss: 0.9320 - val_acc: 0.6531\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.5390 - acc: 0.7712 - val_loss: 0.7966 - val_acc: 0.6327\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.5976 - acc: 0.7319 - val_loss: 0.8408 - val_acc: 0.6531\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.5853 - acc: 0.7580 - val_loss: 0.8140 - val_acc: 0.6939\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.5801 - acc: 0.7464 - val_loss: 0.6977 - val_acc: 0.6735\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.5439 - acc: 0.7492 - val_loss: 0.8720 - val_acc: 0.7143\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.5106 - acc: 0.8037 - val_loss: 0.8048 - val_acc: 0.7347\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.4638 - acc: 0.7799 - val_loss: 0.8559 - val_acc: 0.7143\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.5155 - acc: 0.7891 - val_loss: 0.7802 - val_acc: 0.6735\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.4619 - acc: 0.8472 - val_loss: 0.8735 - val_acc: 0.6531\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 2s 305ms/step - loss: 0.4691 - acc: 0.8000 - val_loss: 0.9657 - val_acc: 0.6531\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.4573 - acc: 0.7880 - val_loss: 0.7445 - val_acc: 0.6735\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 0.5839 - acc: 0.7446 - val_loss: 0.9299 - val_acc: 0.6939\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.3909 - acc: 0.8601 - val_loss: 0.8636 - val_acc: 0.6939\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.4891 - acc: 0.7815 - val_loss: 0.9137 - val_acc: 0.6939\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.4506 - acc: 0.7863 - val_loss: 0.8054 - val_acc: 0.6735\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.4864 - acc: 0.7937 - val_loss: 0.9296 - val_acc: 0.6735\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.4460 - acc: 0.8094 - val_loss: 0.7597 - val_acc: 0.6939\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 2s 312ms/step - loss: 0.4674 - acc: 0.7812 - val_loss: 0.8052 - val_acc: 0.7143\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.4449 - acc: 0.7964 - val_loss: 0.8407 - val_acc: 0.7551\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.4709 - acc: 0.8400 - val_loss: 0.7973 - val_acc: 0.7551\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.4817 - acc: 0.7796 - val_loss: 0.8819 - val_acc: 0.6939\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 2s 303ms/step - loss: 0.4368 - acc: 0.8125 - val_loss: 0.8349 - val_acc: 0.6939\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.4132 - acc: 0.8037 - val_loss: 0.7492 - val_acc: 0.6735\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.4585 - acc: 0.7764 - val_loss: 0.8644 - val_acc: 0.7143\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.4165 - acc: 0.8472 - val_loss: 0.8226 - val_acc: 0.6939\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 2s 309ms/step - loss: 0.3722 - acc: 0.8125 - val_loss: 0.9088 - val_acc: 0.7347\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.3648 - acc: 0.8250 - val_loss: 0.9444 - val_acc: 0.7143\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 1s 287ms/step - loss: 0.3932 - acc: 0.7955 - val_loss: 0.7794 - val_acc: 0.7347\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.4176 - acc: 0.8100 - val_loss: 0.9008 - val_acc: 0.7551\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.4661 - acc: 0.8043 - val_loss: 0.8093 - val_acc: 0.6531\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.4252 - acc: 0.8029 - val_loss: 0.8854 - val_acc: 0.7551\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.4286 - acc: 0.8082 - val_loss: 0.8653 - val_acc: 0.6735\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.4673 - acc: 0.7964 - val_loss: 0.7969 - val_acc: 0.6327\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.4695 - acc: 0.7863 - val_loss: 1.0966 - val_acc: 0.6735\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.5004 - acc: 0.7937 - val_loss: 0.7175 - val_acc: 0.7347\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.4644 - acc: 0.7991 - val_loss: 0.9333 - val_acc: 0.7347\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 2s 306ms/step - loss: 0.4076 - acc: 0.8563 - val_loss: 0.7545 - val_acc: 0.7143\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.4208 - acc: 0.7972 - val_loss: 0.8194 - val_acc: 0.7347\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 0.3570 - acc: 0.8492 - val_loss: 0.8559 - val_acc: 0.7143\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.3161 - acc: 0.8573 - val_loss: 0.9427 - val_acc: 0.7347\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 1s 298ms/step - loss: 0.3464 - acc: 0.8492 - val_loss: 0.7835 - val_acc: 0.7347\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.3614 - acc: 0.8342 - val_loss: 0.8632 - val_acc: 0.6939\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.3872 - acc: 0.8290 - val_loss: 0.9383 - val_acc: 0.7347\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.3880 - acc: 0.7983 - val_loss: 0.8396 - val_acc: 0.6735\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.3666 - acc: 0.8319 - val_loss: 0.9538 - val_acc: 0.6939\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.3778 - acc: 0.8629 - val_loss: 0.7871 - val_acc: 0.6531\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.3311 - acc: 0.8654 - val_loss: 0.9297 - val_acc: 0.7347\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 0.3441 - acc: 0.8527 - val_loss: 0.7670 - val_acc: 0.6939\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.3428 - acc: 0.8510 - val_loss: 0.8046 - val_acc: 0.7143\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 0.4420 - acc: 0.8250 - val_loss: 0.7436 - val_acc: 0.6939\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.3124 - acc: 0.8434 - val_loss: 0.9094 - val_acc: 0.6939\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 0.4353 - acc: 0.7845 - val_loss: 0.8683 - val_acc: 0.7143\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.4211 - acc: 0.8336 - val_loss: 0.7966 - val_acc: 0.6531\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.4137 - acc: 0.8146 - val_loss: 0.7849 - val_acc: 0.6939\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.4597 - acc: 0.8110 - val_loss: 0.9176 - val_acc: 0.6939\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 0.3751 - acc: 0.8110 - val_loss: 0.8181 - val_acc: 0.5918\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.3630 - acc: 0.8545 - val_loss: 0.8879 - val_acc: 0.6939\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.3507 - acc: 0.8336 - val_loss: 0.8114 - val_acc: 0.6939\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.4103 - acc: 0.7828 - val_loss: 0.9536 - val_acc: 0.7347\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 1s 287ms/step - loss: 0.3029 - acc: 0.8608 - val_loss: 0.9659 - val_acc: 0.6939\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.3808 - acc: 0.8499 - val_loss: 0.9534 - val_acc: 0.5918\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.3860 - acc: 0.8102 - val_loss: 1.0646 - val_acc: 0.7143\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 1s 295ms/step - loss: 0.3111 - acc: 0.8545 - val_loss: 0.8281 - val_acc: 0.6531\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 0.2977 - acc: 0.9082 - val_loss: 0.8998 - val_acc: 0.6735\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.3133 - acc: 0.8799 - val_loss: 1.0513 - val_acc: 0.6939\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.3430 - acc: 0.8315 - val_loss: 0.8823 - val_acc: 0.6531\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.3687 - acc: 0.8082 - val_loss: 0.9556 - val_acc: 0.6735\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.4424 - acc: 0.8231 - val_loss: 1.0845 - val_acc: 0.6735\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.3014 - acc: 0.8562 - val_loss: 0.9220 - val_acc: 0.6531\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.2931 - acc: 0.9173 - val_loss: 0.8874 - val_acc: 0.6735\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.3263 - acc: 0.8492 - val_loss: 0.9858 - val_acc: 0.6735\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.2984 - acc: 0.8810 - val_loss: 1.0193 - val_acc: 0.6735\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.2656 - acc: 0.8891 - val_loss: 0.8090 - val_acc: 0.6939\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.3152 - acc: 0.8556 - val_loss: 1.1169 - val_acc: 0.6735\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.2559 - acc: 0.9018 - val_loss: 0.9135 - val_acc: 0.6735\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.2883 - acc: 0.8735 - val_loss: 1.0720 - val_acc: 0.6531\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.2676 - acc: 0.8953 - val_loss: 1.1371 - val_acc: 0.6735\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 1s 296ms/step - loss: 0.3212 - acc: 0.8336 - val_loss: 1.2957 - val_acc: 0.6939\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.4150 - acc: 0.8001 - val_loss: 0.9300 - val_acc: 0.6531\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 0.4141 - acc: 0.8336 - val_loss: 1.1758 - val_acc: 0.6939\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.3516 - acc: 0.8464 - val_loss: 0.7158 - val_acc: 0.5918\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.3136 - acc: 0.8799 - val_loss: 1.0984 - val_acc: 0.6939\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.3232 - acc: 0.8555 - val_loss: 0.7394 - val_acc: 0.6122\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 2s 304ms/step - loss: 0.2821 - acc: 0.9082 - val_loss: 0.9721 - val_acc: 0.6939\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.2989 - acc: 0.8824 - val_loss: 0.7673 - val_acc: 0.6531\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 1s 296ms/step - loss: 0.2372 - acc: 0.9000 - val_loss: 0.8678 - val_acc: 0.6939\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.3149 - acc: 0.8608 - val_loss: 0.9937 - val_acc: 0.7143\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.2810 - acc: 0.8980 - val_loss: 0.8199 - val_acc: 0.6531\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.2471 - acc: 0.9018 - val_loss: 1.0189 - val_acc: 0.7143\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 2s 305ms/step - loss: 0.2644 - acc: 0.8500 - val_loss: 0.7793 - val_acc: 0.6735\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.2989 - acc: 0.8908 - val_loss: 0.9300 - val_acc: 0.6735\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 1s 288ms/step - loss: 0.2627 - acc: 0.8891 - val_loss: 1.0540 - val_acc: 0.6939\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.3131 - acc: 0.8608 - val_loss: 1.0162 - val_acc: 0.6531\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.2589 - acc: 0.8953 - val_loss: 1.2229 - val_acc: 0.6735\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.2988 - acc: 0.8591 - val_loss: 0.8516 - val_acc: 0.6735\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.2530 - acc: 0.8778 - val_loss: 0.9316 - val_acc: 0.6939\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 2s 309ms/step - loss: 0.2517 - acc: 0.8875 - val_loss: 0.8234 - val_acc: 0.7143\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.2085 - acc: 0.9232 - val_loss: 0.9559 - val_acc: 0.6531\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.2855 - acc: 0.8827 - val_loss: 1.2912 - val_acc: 0.6939\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.3488 - acc: 0.8601 - val_loss: 0.9750 - val_acc: 0.6531\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.2422 - acc: 0.9145 - val_loss: 1.0113 - val_acc: 0.6939\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.2829 - acc: 0.8870 - val_loss: 0.9919 - val_acc: 0.6735\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.2899 - acc: 0.8781 - val_loss: 0.8834 - val_acc: 0.7143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjdA7EI9a9lK",
        "colab_type": "code",
        "outputId": "eb86bd4e-d19b-4751-a9e0-b9a6ed3761ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "predictions = model.predict(X)\n",
        "y_pred = (predictions > 0.5)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix =confusion_matrix(y, y_pred.argmax(axis=1))/1.\n",
        "matrix[0,]=matrix[0,]/np.sum(matrix[0,])\n",
        "matrix[1,]=matrix[1,]/np.sum(matrix[1,])\n",
        "matrix[2,]=matrix[2,]/np.sum(matrix[2,])\n",
        "matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [0.61111111, 0.        , 0.38888889]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K8Eeim3bAvW",
        "colab_type": "code",
        "outputId": "60899370-4c28-4f76-bc30-c88db0423bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "skplt.metrics.plot_roc_curve(y, predictions)\n",
        "\n",
        "plt.savefig('Roc2.png')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:85: DeprecationWarning: Function plot_roc_curve is deprecated; This will be removed in v0.5.0. Please use scikitplot.metrics.plot_roc instead.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3nza7fSbDkw",
        "colab_type": "code",
        "outputId": "aae0f07f-d165-408c-caaf-77c47738623b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-31 19:35:30--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 35.174.75.106, 3.234.122.223, 35.153.11.252, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|35.174.75.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   0%[                    ]  96.52K   377KB/s               \r        ngrok-stabl   6%[>                   ] 893.53K  1.70MB/s               \r       ngrok-stable  49%[========>           ]   6.44M  8.38MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  14.0MB/s    in 0.9s    \n",
            "\n",
            "2019-12-31 19:35:32 (14.0 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0nPip65bHS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = 'logs/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6005 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB-4ZwWubKeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6005 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7WaB6Z1bNAs",
        "colab_type": "code",
        "outputId": "bbc93158-76b9-442b-f5c8-8ef7c7998666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://15102f6c.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr6csQ1dfYgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ssingh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdCks1wGfgvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp -r /content/Roc2.png /content/ssingh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW1jLAR7gaEQ",
        "colab_type": "code",
        "outputId": "00dc0484-59a6-46b7-9c20-7c6e88b2a8ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqkjKHiggozB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp -r /content/ssingh  /content/drive/My\\ Drive/quaternion"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}